{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahin-Alam2/AI/blob/main/Group6_Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunCkFFwlhz4"
      },
      "source": [
        "# Importing Necessary Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djoieDYC5NbU",
        "outputId": "37a99b54-fb1b-4004-a366-5bb8d64cf780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import vgg16, ResNet50\n",
        "from keras.layers import Conv2D, Input, Dense, Activation, MaxPooling2D, Flatten, AveragePooling2D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from keras.utils import to_categorical\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW_rJZ3klmzG"
      },
      "source": [
        "# Fetching Peace and Thumbs Up Data, Labeling Peace as 0, and Thumbs Up as 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xhil5PVDaAy"
      },
      "outputs": [],
      "source": [
        "#reading data and labeling it\n",
        "DIRECTORY = '/content/drive/MyDrive/thumbsup_peace'\n",
        "CATEGORIES = ['peace_test', 'peace_train', 'thumbsup_test', 'thumbsup_train']\n",
        "train_data = []\n",
        "test_data = []\n",
        "test_count = 0\n",
        "train_count = 0\n",
        "for category in CATEGORIES:\n",
        "  folder = os.path.join(DIRECTORY, category)\n",
        "  label = CATEGORIES.index(category) // 2\n",
        "  # print(label)\n",
        "  splited_name = category.split('_')\n",
        "  # print(splited_name[1])\n",
        "\n",
        "  if(splited_name[1] == \"train\"):\n",
        "    # print(category)\n",
        "      for img in os.listdir(folder):\n",
        "        image = os.path.join(folder, img)\n",
        "        image_arr = cv2.imread(image)\n",
        "        image_arr = cv2.resize(image_arr, (224, 224))\n",
        "        train_data.append([image_arr, label])\n",
        "        train_count = train_count+1\n",
        "  else:\n",
        "    # print(\"test\")\n",
        "    for img in os.listdir(folder):\n",
        "      image = os.path.join(folder, img)\n",
        "      image_arr = cv2.imread(image)\n",
        "      image_arr = cv2.resize(image_arr, (224, 224))\n",
        "      test_data.append([image_arr, label])\n",
        "      test_count = test_count+1\n",
        "\n",
        "print('Number of total train data: ', train_count)\n",
        "print('Number of test data: ', test_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXExlskdlwZS"
      },
      "source": [
        "# Making np array X_train_val and Y_train_val from train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Qn1jjaOYmx"
      },
      "outputs": [],
      "source": [
        "#making x and y from read data and label\n",
        "random.shuffle(train_data)\n",
        "x_train_val = []\n",
        "y_train_val = []\n",
        "\n",
        "for features,label in train_data:\n",
        "  x_train_val.append(features)\n",
        "  y_train_val.append(label)\n",
        "\n",
        "#converitn x and y list to np array\n",
        "x_train_val = np.array(x_train_val)\n",
        "y_train_val = np.array(y_train_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD2Gt_iqbFgh"
      },
      "source": [
        "# Making np array x_tes and y_test from test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHhv3efRbMwQ"
      },
      "outputs": [],
      "source": [
        "#making x and y from read data and label\n",
        "random.shuffle(test_data)\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for features,label in test_data:\n",
        "  x_test.append(features)\n",
        "  y_test.append(label)\n",
        "\n",
        "#converitn x and y list to np array\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khy6bGLmwL1O"
      },
      "source": [
        "# Plotting X_train_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rUYQDrlwOOp"
      },
      "outputs": [],
      "source": [
        "flatten_images = x_train_val.ravel()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(flatten_images, color='black', alpha=0.7)\n",
        "plt.title('Histogram of Pixel Of X_train_val Intensities Before Normalization', fontsize=16)\n",
        "plt.xlabel('Pixel Intensity', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the highest and lowest intensity of pixel\n",
        "print(f'Highest intensity of pixel: {np.max(flatten_images)}')\n",
        "print(f'Lowest intensity of pixel: {np.min(flatten_images)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulmr61uNban2"
      },
      "source": [
        "# Plotting X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZGTqEc2befM"
      },
      "outputs": [],
      "source": [
        "flatten_images = x_test.ravel()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(flatten_images, color='black', alpha=0.7)\n",
        "plt.title('Histogram of Pixel Of X_test Intensities Before Normalization', fontsize=16)\n",
        "plt.xlabel('Pixel Intensity', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the highest and lowest intensity of pixel\n",
        "print(f'Highest intensity of pixel: {np.max(flatten_images)}')\n",
        "print(f'Lowest intensity of pixel: {np.min(flatten_images)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFfMnfATtW_n"
      },
      "source": [
        "#Normalizing x_train_val and Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTADn6kntb0z"
      },
      "outputs": [],
      "source": [
        "#normalizing x\n",
        "x_train_val = x_train_val/255.0\n",
        "\n",
        "# Assuming x is your array of images with shape (1012, 224, 224, 3)\n",
        "# Flatten each image and concatenate them into a single array\n",
        "flatten_images = x_train_val.ravel()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(flatten_images, color='black', alpha=0.7)\n",
        "plt.title('Histogram of x_train_val Pixel Intensities After Normalization', fontsize=16)\n",
        "plt.xlabel('Pixel Intensity', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the highest and lowest intensity of pixel\n",
        "print(f'Highest intensity of pixel: {np.max(flatten_images)}')\n",
        "print(f'Lowest intensity of pixel: {np.min(flatten_images)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcwvC_eYduKB"
      },
      "source": [
        "#Normalizing x_test and Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaUrA4mFdkbv"
      },
      "outputs": [],
      "source": [
        "#normalizing x\n",
        "x_test = x_test/255.0\n",
        "\n",
        "# Assuming x is your array of images with shape (1012, 224, 224, 3)\n",
        "# Flatten each image and concatenate them into a single array\n",
        "flatten_images = x_test.ravel()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(flatten_images, color='black', alpha=0.7)\n",
        "plt.title('Histogram of x_test Pixel Intensities After Normalization', fontsize=16)\n",
        "plt.xlabel('Pixel Intensity', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the highest and lowest intensity of pixel\n",
        "print(f'Highest intensity of pixel: {np.max(flatten_images)}')\n",
        "print(f'Lowest intensity of pixel: {np.min(flatten_images)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxs8TG5wpYjK"
      },
      "source": [
        "# Splitting Train and Validation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6j27uEwmajV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqaFAm9IpeQB"
      },
      "outputs": [],
      "source": [
        "# x_train, x_val, y_train, y_val  = train_test_split(x_train_val, y_train_val, test_size=0.1)\n",
        "x_train = x_train_val[:int(len(x_train_val)*.9)]\n",
        "x_val = x_train_val[-int(len(x_train_val)*.1):]\n",
        "y_train = y_train_val[:int(len(y_train_val)*.9)]\n",
        "y_val = y_train_val[-int(len(y_train_val)*.1):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G6GnQFe0dci"
      },
      "source": [
        "# Plotting y_train, y_val and y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqfolWZB0jGx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y_train, color='Black', alpha=0.7)\n",
        "plt.title('Number Of thumbs and Peace Sign in Train Set', fontsize=16)\n",
        "plt.xlabel('Class       Peace(0)          ThumbsUp(1)', fontsize=14)\n",
        "plt.ylabel('Number Of Objects In Each Class', fontsize=14)\n",
        "plt.grid('true')\n",
        "\n",
        "# Get the counts of objects in each class\n",
        "counts = np.bincount(y_train)\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRp00hUB1t8H"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y_val, color='Black', alpha=0.7)\n",
        "plt.title('Number Of thumbs and Peace Sign in Validation Set', fontsize=16)\n",
        "plt.xlabel('Class       Peace(0)          ThumbsUp(1)', fontsize=14)\n",
        "plt.ylabel('Number Of Objects In Each Class', fontsize=14)\n",
        "plt.grid('true')\n",
        "counts = np.bincount(y_val)\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GByR_H7116dN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y_test, color='Black', alpha=0.7)\n",
        "plt.title('Number Of thumbs and Peace Sign in Test Set', fontsize=16)\n",
        "plt.xlabel('Class       Peace(0)          ThumbsUp(1)', fontsize=14)\n",
        "plt.ylabel('Number Of Objects In Each Class', fontsize=14)\n",
        "plt.grid('true')\n",
        "counts = np.bincount(y_test)\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX93uKuQ_GbS"
      },
      "source": [
        "# Printing The Shapes of Train, Test and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu9sMJr8_Mxl"
      },
      "outputs": [],
      "source": [
        "print('Shape of x_train', np.shape(x_train))\n",
        "print('Shape of x_val', np.shape(x_val))\n",
        "print('Shape of x_test', np.shape(x_test))\n",
        "print('Shape of y_train', np.shape(y_train))\n",
        "print('Shape of y_val', np.shape(y_val))\n",
        "print('Shape of y_test', np.shape(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZWNy0rboZNC"
      },
      "source": [
        "# Extending Vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1lnURlCoYfe"
      },
      "outputs": [],
      "source": [
        "vgg16_model = tf.keras.applications.VGG16(\n",
        "    weights='imagenet',  # You can use 'imagenet' to load ImageNet pre-trained weights\n",
        "    include_top=False,   # Exclude the top (fully connected) layers\n",
        "    input_shape=(224, 224, 3)  # Specify the input shape of your images\n",
        ")\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(vgg16_model)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe4GkXembsx6"
      },
      "source": [
        "# Showing Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5GL7DpPbsJ1"
      },
      "outputs": [],
      "source": [
        "# Plot and display the model architecture in the notebook\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJNaZcKtmOIj"
      },
      "source": [
        "# Trainning The model with x and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDzu0nl21QD6"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg4oKHvFD-BP"
      },
      "outputs": [],
      "source": [
        "performance_dict = history.history\n",
        "print(performance_dict.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnVTzTC9GhJS"
      },
      "source": [
        "# Check The Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FSqEupuEfG8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(performance_dict ['loss'], color='purple', label='Train Loss')\n",
        "plt.plot(performance_dict ['val_loss'], color='orange', label='Validation Loss')\n",
        "plt.legend(loc='upper right', fontsize=20)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.grid(color='blue', linewidth=0.3, linestyle='--')\n",
        "plt.title('Train Loss vs Validation Loss', fontsize=16)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(performance_dict ['accuracy'], color='purple', label='Train Accuracy')\n",
        "plt.plot(performance_dict ['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "plt.legend(loc='lower right', fontsize=20)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.grid(color='blue', linewidth=0.3, linestyle='--')\n",
        "plt.title('Train Accuracy vs Validation Accuracy', fontsize=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXSI86Y-ryxC"
      },
      "source": [
        "# Evaluate The Model On Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxJ5056yrdkK"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(x_val, y_val)\n",
        "# print(model.metrics_names)\n",
        "print('Evaluating The Model On Validation Data')\n",
        "print(model.metrics_names[1], scores[1]*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alIACMx9tuO5"
      },
      "source": [
        "# Check What the model actually predicts In Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_he-tqXt0Q7"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_val[26])\n",
        "print(y_val[26])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huzp2epUvvmy"
      },
      "source": [
        "# Check What the model predicts in Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is4mSsBHutQq"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_9BhHtP450C"
      },
      "outputs": [],
      "source": [
        "prediction[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN0e4-biUuw_"
      },
      "outputs": [],
      "source": [
        "y_test[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EX9TGrUxFh6"
      },
      "outputs": [],
      "source": [
        "y_predicted = []\n",
        "# length = prediction.shape[0]\n",
        "for i in range(prediction.shape[0]):\n",
        "  if(prediction[i][0] > prediction[i][1]):\n",
        "    y_predicted.append(0)\n",
        "  else:\n",
        "    y_predicted.append(1)\n",
        "\n",
        "y_predicted_text = []\n",
        "for i in range(len(y_predicted)):\n",
        "  if(y_predicted[i] == 0):\n",
        "    y_predicted_text.append('Peace')\n",
        "  else:\n",
        "    y_predicted_text.append('Thumbs Up')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ur7NwGU1Eu-"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_test[20])\n",
        "print(y_predicted_text[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp2VJl5h0iuG"
      },
      "source": [
        "# Evaluate The Model On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snbs-M5F0BVN"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(x_test, y_test)\n",
        "# print(model.metrics_names)\n",
        "print('Evaluating The Model On Test Data')\n",
        "print(model.metrics_names[0], scores[0]*100)\n",
        "print(model.metrics_names[1], scores[1]*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV8Ff8S75k5N"
      },
      "source": [
        "# Confussion Matrix Of CNN Based Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pga-neeG5qXs"
      },
      "outputs": [],
      "source": [
        "y_predicted\n",
        "actual = y_test\n",
        "conf_mat = confusion_matrix(actual, y_predicted)\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
        "# Increase the font size using the display_labels parameter\n",
        "displ.plot(xticks_rotation='horizontal', values_format=\".0f\")\n",
        "\n",
        "# Increase the font size of the labels\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "# Increase the font size of the xlabel and ylabel\n",
        "plt.xlabel('Predicted Labels', fontsize=14)\n",
        "plt.ylabel('True Labels', fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRq_vUTAv2wj"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov3o45GVvqMn"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "model = Sequential()\n",
        "model.add(ResNet50(include_top=False, pooling='max', weights=\"imagenet\"))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "# ResNet-50 model is already trained, should not be trained\n",
        "model.layers[0].trainable = False\n",
        "model.compile(optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi72aHpty3az"
      },
      "outputs": [],
      "source": [
        "# Plot and display the model architecture in the notebook\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b801FI6wyAdP"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot encoding\n",
        "num_classes = 2\n",
        "y_train_onehot = to_categorical(y_train, num_classes=num_classes)\n",
        "y_val_onehot = to_categorical(y_val, num_classes=num_classes)\n",
        "y_test_onehot = to_categorical(y_test, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gui7OPKQv12V"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train_onehot, epochs=100, validation_data=(x_val, y_val_onehot), batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stHONXQdz0ph"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(performance_dict ['loss'], color='purple', label='Train Loss')\n",
        "plt.plot(performance_dict ['val_loss'], color='orange', label='Validation Loss')\n",
        "plt.legend(loc='upper right', fontsize=20)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.grid(color='blue', linewidth=0.3, linestyle='--')\n",
        "plt.title('Train Loss vs Validation Loss', fontsize=16)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(performance_dict ['accuracy'], color='purple', label='Train Accuracy')\n",
        "plt.plot(performance_dict ['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "plt.legend(loc='lower right', fontsize=20)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.grid(color='blue', linewidth=0.3, linestyle='--')\n",
        "plt.title('Train Accuracy vs Validation Accuracy', fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEIy2Gbd0uq-"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(x_test, y_test_onehot)\n",
        "# print(model.metrics_names)\n",
        "print('Evaluating The Model On Test Data')\n",
        "print(model.metrics_names[0], scores[0]*100)\n",
        "print(model.metrics_names[1], scores[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGwEpgu21Fwa"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3mW9Tjb1IjC"
      },
      "outputs": [],
      "source": [
        "y_predicted = []\n",
        "# length = prediction.shape[0]\n",
        "for i in range(prediction.shape[0]):\n",
        "  if(prediction[i][0] > prediction[i][1]):\n",
        "    y_predicted.append(0)\n",
        "  else:\n",
        "    y_predicted.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRsHyQIa05BL"
      },
      "outputs": [],
      "source": [
        "y_predicted\n",
        "actual = y_test\n",
        "conf_mat = confusion_matrix(actual, y_predicted)\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
        "# Increase the font size using the display_labels parameter\n",
        "displ.plot(xticks_rotation='horizontal', values_format=\".0f\")\n",
        "\n",
        "# Increase the font size of the labels\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "# Increase the font size of the xlabel and ylabel\n",
        "plt.xlabel('Predicted Labels', fontsize=14)\n",
        "plt.ylabel('True Labels', fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}